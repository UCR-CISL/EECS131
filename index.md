---
layout: default
title: Overview
---

{% include course_title.html %}


### Course Description
Edge is a computing paradigm that takes the business logic (computation and data storage) to the "edge" of the network. 
This means doing all or most processing at the same level the data is generated, specifically in the context of real life applications. 
It is somehow a fluid concept of recent creation, but the challenges it brings and the potential for future development are pretty clear. 
The IoT world is constantly generating all kinds of information that requires near to instant response. 
This brings interesting new challenges to how we look at computational design. 

In this course, we are focusing on the practical aspects of Edge Computing.  
Exploiting limited resources in an efficient and effective manner. 
We will focus on how to make applications work at the Edge as well as 
discussing high level concepts on topics like privacy, performance, security, latency, and their relevance to Edge Computing.

After taking this course, you should be able to:

- Describe the structure and components of and Edge Network
- Make decisions on workload distribution between Edge devices and Cloud resources
- Understand and identify the priorities of Edge Computing in different scenarios and use cases 
- Analyze and profile different architectures that will aid on processing the data
- Draw cost-benefit analysis where resources are limited
- Design an Edge ML application (e.g. AR/VR, health care, self-driving cars)


#### Textbooks
The following are textbooks used as reference for this class. While useful, they are not required.
- Situnayake, D., & Plunkett, J. (2023). AI at the Edge. O'Reilly
- Buyya, R., & Srirama, S. N. (Eds.). (2019). Fog and edge computing: principles and paradigms. John Wiley & Sons.
- Al-Turjman, F. (2019). Edge computing: From Hype to Reality. Springer